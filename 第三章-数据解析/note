聚焦爬虫：爬取页面中指定的页面内容
    - 编码流程:
        - 指定url
        - 发起请求
        - 获取响应数据
        - 数据解析
        - 持久化存储


数据解析分类：
    -正则
    -bs4
    -xpath（***）

数据解析原理概述：
    - 解析局部文本内容都会在标签之间或者标签对应的属性中进行存储
    - 1.进行指定标签的定位
    - 2.标签或者标签对应的属性中存储的数据进行提取（解析）

bs4进行数据解析
    - 数据解析的原理：
        - 1.标签定位
        - 2.提取标签、标签属性中存储的数据值
    - bs4数据解析的原理：
        - 1.实例化一个BeautifulSoup对象，并且将页面源代码数据加载到该对象中
        - 2.通过调用BeautifulSoup对象中相关的属性或者方法进行标签定位或数据提取
    - 环境安装：
        - pip install bs4
        - pip install lxml
    - 如何实例化BeautifulSoup对象：
        - from bs4 import BeautifulSoup
        - 对象的实例化：
            - 1.将本地的html文档中的数据加载到该对象中
                fp=open('./test.html','r',encoding='utf-8')
                soup=BeautifulSoup(fp,'lxml')

            - 2.将互联网上获取的页面源码加载到该对象中
                page_text=response.text
                soup=BeautifulSoup(page_text,'lxml')
            - 提供的用于数据解析的方法和属性：
                - soup.tagName:返回的是文档中第一次出现的tagName对应的标签
                - soup.find():
                    - find('tagName'):等同于soup.tagName
                    - 属性定位：
                        - soup.find('div',class_/id/attr=?)
                - soup.find_all('tagName'):返回符合要求的所有标签(列表)
                -select:
                    - select('某个选择器(id,class,标签)'),返回的是一个列表
                    - 层级选择器：
                        - soup.select('div > ul > li'):表示的是一个层级
                        - soup.select('div >ul  a'):空格表示多个层级

                - 获取标签之间的文本数据
                    - soup.a.text/string/get_text()
                    - text/get_text():可以获取某一个标签中所有的文本内容
                    - string:只可以获取该标签下面直系的文本内容
                - 获取标签中的属性值
                    - soup.a['href']